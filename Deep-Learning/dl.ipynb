{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning: An Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we gonna see in this workshop?\n",
    "\n",
    "- Understand what DL is, how it is different from ML, and why it is so effective.\n",
    "- Understand the Perceptron algorithm and how it is the building block for a Neural Network.\n",
    "- Explore prominent DL architectures in Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install matplotlib numpy torch torchvision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Hyperparameters \n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_layers = 2\n",
    "sequence_length = 28\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST Dataset\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data loader\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset)\n",
    "print(test_dataset)\n",
    "print(train_loader)\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Deep Learning?\n",
    "\n",
    "- **The Objective of ML**: Build intelligent systems by extracting patterns from raw data. Build a **hierarchy of concepts**, with each concept being built out of simpler ones. \n",
    "- **Deep Learning**: The hierarchy of concepts allows complicated concepts to be built out of simpler ones, and the **graph** representing the relations b/w concepts is very deep. Hence the name 'Deep' Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is Deep Learning Necessary?\n",
    "\n",
    "- Performance of ML algorithms depends heavily on the *representation of the data*. The representation is composed of many pieces of information on the data point, also known as **features** of the data point.\n",
    "\n",
    "- A simple algorithm for building AI:\n",
    "    1. Design appropriate set of features for the task.\n",
    "    2. Feed the data to an ML algorithm\n",
    "\n",
    "- **The Problem**: *It is often difficult to construct features for certain problems*. If for example we wanted to recognize wheels on cars, it is not easy to describe what wheels look like in terms of pixel values.\n",
    "\n",
    "- One solution is to use ML to learn the representations themselves. This is called **representation learning**. But it can be difficult to obtain such a representation. This is where Deep Learning helps us; *it introduces representations in terms of simpler representations*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Perceptron\n",
    "\n",
    "<img src=https://miro.medium.com/max/732/1*74YD-gADYB8xC7MQ36apFA.jpeg width=\"200\">\n",
    "\n",
    "- Simple model of computation that takes in several binary inputs $x_1, x_2, \\dots, x_n$ and their corresponding weights $w_1, w_2, \\dots, w_n$ and produces a single binary output. The output depends on whether the weighted sum of the inputs is above or below a *threshold* value.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "  \\mbox{output} & = & \\left\\{ \\begin{array}{ll}\n",
    "      1 & \\mbox{if } \\sum_j w_j x_j\\geq \\mbox{ threshold} \\\\\n",
    "      0 & \\mbox{if } \\sum_j w_j x_j< \\mbox{ threshold}\n",
    "      \\end{array} \\right.\n",
    "\\tag{1}\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "- **Intuition**: Just a device that makes a decision by *weighing* up evidence.\n",
    "- Varying the weights and the thresholds can allow us to produce different models of decision making.\n",
    "\n",
    "- Extending this idea to a network of perceptrons allows us to make more abstract and complex decisions:\n",
    "![](http://neuralnetworksanddeeplearning.com/images/tikz1.png)\n",
    "\n",
    "- **Rewriting the Perceptron equation with a bias**:\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "  \\mbox{output} & = & \\left\\{ \\begin{array}{ll}\n",
    "      1 & \\mbox{if } \\sum_j w_j x_j + b \\geq \\mbox{ threshold} \\\\\n",
    "      0 & \\mbox{if } \\sum_j w_j x_j + b < \\mbox{ threshold}\n",
    "      \\end{array} \\right.\n",
    "\\tag{1}\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "- **Intuition**: The bias is a measure of how easy it is for the perceptron to output a 1. \n",
    "\n",
    "<img src=https://miro.medium.com/max/15164/1*-oWHnqj0hjipXyeaUy8k8A.jpeg width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Algorithms\n",
    "\n",
    "- **Core Idea**: Automatically tune the weights and biases of the network of neurons.\n",
    "- **Problem**: Small changes in the weights and biases might cause the output of the perceptron to flip completely.\n",
    "\n",
    "#### The Sigmoid Neuron\n",
    "- Similar to perceptrons, but add an extra layer of functionality: it can take any input between 0 and 1, and makes sure that small changes in the weights and biases cause small changes in the output.\n",
    "- The equation becomes $\\sigma(w \\cdot x + b)$, where\n",
    "$$\n",
    "\\begin{eqnarray} \n",
    "  \\sigma(z) \\equiv \\frac{1}{1+e^{-z}}.\n",
    "\\tag{2}\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray} \n",
    "  \\Delta \\mbox{output} \\approx \\sum_j \\frac{\\partial \\, \\mbox{output}}{\\partial w_j}\n",
    "  \\Delta w_j + \\frac{\\partial \\, \\mbox{output}}{\\partial b} \\Delta b,\n",
    "\\tag{3}\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "#### Generalizing the Notion: Activation Functions\n",
    "- $f(w \\cdot x + b)$, where $f$ is the activation function. Allows us to control the values of the partial derivatives in Eq.3. For instance, the sigmoid activation function is popular because *exponentials have lovely properties when differentiated*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Neural Network (a.k.a Multilayered Perceptrons)\n",
    "\n",
    "![](http://neuralnetworksanddeeplearning.com/images/tikz11.png)\n",
    "\n",
    "- Consists of three types of layers: **input layers, hidden layers, and output layer**.\n",
    "- Each neuron in a layer is connected to every neuron in the next layer.\n",
    "- The output of one layer is used as the input to the next layer. That's why we call them **feedforward neural networks**. There are no loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning using Gradient Descent and Backpropagation\n",
    "\n",
    "- Necessary to define a loss function quantize the difference between the desired output and the actual output. There are various choices such as RMSE, SVM, and Hinge loss.\n",
    "\n",
    "- *Our objective is to minimize the loss function*. This is done by moving in the negative direction of the gradient.\n",
    "\n",
    "$$\n",
    "x_{t+1} = x_t - \\eta_t \\nabla f(x_t)\n",
    "$$\n",
    "\n",
    "where $\\eta_t$ and $\\nabla f(x_t)$ is the learning rate and gradient of the cost function respectively at time $t$\n",
    "\n",
    "- Notice that we need to update the parameters corresponding to each neuron in the network. But, how does one compute the derivatives when we have multiple layers? We use the chain rule!\n",
    "- We start with the derivative of the loss function with respect to the last layer and then 'propagate' thoseerrors backward through the hidden layers until we arrive at the input layer. This process is called **backpropagation**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('Ilg3gGewQ5U', width=1000, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to see better: Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://cs231n.github.io/assets/cnn/cnn.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Convolution Layer\n",
    "\n",
    "#### What does it do?\n",
    "- Consists of a set of **learnable filters**. Will be small spatially along the width and height, but extends across the entire depth.\n",
    "- **Process**: Slide the filter across the input volume and compute dot products between the entries of the filter and the corresponding input. This produces a **2D activation map**. \n",
    "- **Intuition**: Network learns filters that activate in response to visual stimuli, such as an edge or a colored blotch. Each layer will have an entire set of filters that we stack on top of each to produce the output volume.\n",
    "\n",
    "![](https://miro.medium.com/max/1052/1*GcI7G-JLAQiEoCON7xFbhg.gif)\n",
    "\n",
    "#### Local Connectivity\n",
    "- Impractical to connect each neuron to all neurons in the previous volume. Instead, we connect each neuron to a local region of the input volume. The spatial extent of this is a hyperparameter called the **receptive field** of the neuron. \n",
    "\n",
    "- The following hyperparameters control the size of the output volume:\n",
    "1. **Depth**: The number of filters we would like to use, each learning to look for something different in the input.\n",
    "2. **Stride**: The stride with which we slide the filter.\n",
    "3. **Zero Padding**: Sometimes, it is convenient to pad the input volume with zeros around the border to control the size of the output volume. The size of this zero padding is a hyperparameter.\n",
    "\n",
    "Let $W$ be the input volume size, $F$ be the receptive field size of the filters, $S$ be the stride of the filters, and $P$ be the amount of zero padding on the border. The size of the output volume $O$ is:\n",
    "\n",
    "$$\n",
    "O = \\frac{W - F + 2P}{S} + 1\n",
    "$$\n",
    "\n",
    "#### Parameter Sharing\n",
    "- Used to control the number of parameters. The key idea is to make all neurons in a particular feature map share a single set of weights and biases. Makes computation far more efficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pooling Layer\n",
    "- **Purpose:** to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network, and hence to also control overfitting. \n",
    "- There are various types such as max pooling, average pooling, and L2-norm pooling.\n",
    "\n",
    "![](http://cs231n.github.io/assets/cnn/maxpool.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Fully Connected Layer\n",
    "\n",
    "- Neurons in a fully connected layer have full connections to all activations in the previous layer, as seen in regular Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a CNN (two-layers) with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pytorch is an open source library developed by Facebook for machine learning, natural language processing and more.\n",
    "- You can also try out some other popular DL libraries such as Tensorflow (and Keras, a wrapper for Tensorflow) and Theanos. These libraries provide different levels of readabilities and abstraction for you to build neural networks like building blocks.\n",
    "- High suggest beginners to try out Pytorch and Keras (more high level) first before moving into the details of Tensorflow APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "        self.features = [self.layer1, self.layer2, self.fc]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ConvNet instance\n",
    "model = ConvNet(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes)\n",
    "model.load_state_dict(torch.load('cnnmodel.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'cnnmodel.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the filers of our ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filters_single_channel(t):\n",
    "    \n",
    "    #kernels depth * number of kernels\n",
    "    nplots = t.shape[0]*t.shape[1]\n",
    "    ncols = 12\n",
    "    \n",
    "    nrows = 1 + nplots//ncols\n",
    "    #convert tensor to numpy image\n",
    "    npimg = np.array(t.numpy(), np.float32)\n",
    "    \n",
    "    count = 0\n",
    "    fig = plt.figure(figsize=(ncols, nrows))\n",
    "    \n",
    "    #looping through all the kernels in each channel\n",
    "    for i in range(t.shape[0]):\n",
    "        for j in range(t.shape[1]):\n",
    "            count += 1\n",
    "            ax1 = fig.add_subplot(nrows, ncols, count)\n",
    "            npimg = np.array(t[i, j].numpy(), np.float32)\n",
    "            npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
    "            npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
    "            ax1.imshow(npimg)\n",
    "            ax1.set_title(str(i) + ',' + str(j))\n",
    "            ax1.axis('off')\n",
    "            ax1.set_xticklabels([])\n",
    "            ax1.set_yticklabels([])\n",
    "   \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filters_multi_channel(t):\n",
    "    \n",
    "    #get the number of kernals\n",
    "    num_kernels = t.shape[0]    \n",
    "    \n",
    "    #define number of columns for subplots\n",
    "    num_cols = 12\n",
    "    #rows = num of kernels\n",
    "    num_rows = num_kernels\n",
    "    \n",
    "    #set the figure size\n",
    "    fig = plt.figure(figsize=(num_cols,num_rows))\n",
    "    \n",
    "    #looping through all the kernels\n",
    "    for i in range(t.shape[0]):\n",
    "        ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
    "        \n",
    "        #for each kernel, we convert the tensor to numpy \n",
    "        npimg = np.array(t[i].numpy(), np.float32)\n",
    "        #standardize the numpy image\n",
    "        npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
    "        npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
    "        npimg = npimg.transpose((1, 2, 0))\n",
    "        ax1.imshow(npimg)\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title(str(i))\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "          \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights(model, layer_num, single_channel = True, collated = False):\n",
    "  \n",
    "    #extracting the model features at the particular layer number\n",
    "    layer = model.features[layer_num][0]\n",
    "\n",
    "    #checking whether the layer is convolution layer or not \n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        #getting the weight tensor data\n",
    "        weight_tensor = model.features[layer_num][0].weight.data\n",
    "\n",
    "        if single_channel:\n",
    "            if collated:\n",
    "                plot_filters_single_channel_big(weight_tensor)\n",
    "            else:\n",
    "                plot_filters_single_channel(weight_tensor)\n",
    "\n",
    "        else:\n",
    "            if weight_tensor.shape[1] == 3:\n",
    "                plot_filters_multi_channel(weight_tensor)\n",
    "            else:\n",
    "                print(\"Can only plot weights with three channels with single channel = False\")\n",
    "\n",
    "    else:\n",
    "        print(\"Can only visualize layers which are convolutional\")\n",
    "        \n",
    "#visualize weights for 1st convolutional layers\n",
    "plot_weights(model, 0, single_channel = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the convolved image (feature map) for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model.features[0][0].register_forward_hook(get_activation('conv1'))\n",
    "model.features[1][0].register_forward_hook(get_activation('conv2'))\n",
    "data, _ = test_dataset[0]\n",
    "data.unsqueeze_(0)\n",
    "output = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the convolved image for the first conv layer (16 kernels)\n",
    "act = activation['conv2'].squeeze()\n",
    "num_cols = 4\n",
    "num_rows = act.size(0)\n",
    "fig = plt.figure(figsize = (20,100))\n",
    "\n",
    "for i in range(act.size(0)):\n",
    "    ax1 = fig.add_subplot(num_rows,num_cols,i + 1)\n",
    "    ax1.set_title(str(i))\n",
    "    ax1.imshow(act[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- \"MIT Deep Learning Basics: Introduction and Overview with TensorFlow\" https://medium.com/tensorflow/mit-deep-learning-basics-introduction-and-overview-with-tensorflow-355bcd26baf0\n",
    "- \"Chapter 1: An Introduction to Deep Learning\" http://www.deeplearningbook.org/contents/intro.html\n",
    "- \"Chapter 2: How the Backpropagation algorithm works?\": http://neuralnetworksanddeeplearning.com/chap2.html\n",
    "- \"Deep Learning with PyTorch: A 60-Minute Blitz\" https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "- \"Neural Networks and Deep Learning\": http://neuralnetworksanddeeplearning.com/chap1.html\n",
    "- \"Convolutional Neural Networks\": http://cs231n.github.io/convolutional-networks/\n",
    "- \"3Blue1Brown Neural networks\": https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
